{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/joenwa/NLP_PRACTICE_IN_DH/blob/main/My_Learning_Sentiment_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sentiment Analysis\n",
        "\n",
        "---\n",
        "\n",
        "**Definition:**  \n",
        "Sentiment Analysis, often referred to as opinion mining, is the process of determining the emotional tone or subjective information behind a series of words. It is used to gain an understanding of the attitudes, opinions, and emotions expressed within an online mention.\n",
        "\n",
        "---\n",
        "\n",
        "## 📌 **Why is Sentiment Analysis Important?**\n",
        "\n",
        "1. **Business Insights**: Businesses can gain insights into how their customers feel about their products or services, allowing for better decision-making.\n",
        "2. **Market Analysis**: Companies can gauge the reception of their new launches or marketing campaigns.\n",
        "3. **Public Sentiment**: Governments or NGOs can gauge public sentiment on policies or social issues.\n",
        "4. **Personal Projects**: Individuals can use it, for instance, to filter out negative comments from their social media.\n",
        "\n",
        "---\n",
        "\n",
        "## 🛠 **How Does Sentiment Analysis Work?**\n",
        "\n",
        "There are several approaches to sentiment analysis:\n",
        "1. **Lexicon-based**: Counts the number of positive and negative words in a text. The sentiment is determined by the dominant count.\n",
        "2. **Machine Learning-based**: Uses algorithms to learn from labeled data and then predict sentiment on unlabeled data.\n",
        "3. **Hybrid**: Combines both lexicon-based and machine learning approaches.\n",
        "\n",
        "---\n",
        "\n",
        "## 🌐 **Types of Sentiment Analysis**:\n",
        "\n",
        "- **Fine-grained Analysis**: Beyond just positive, negative, or neutral, it may classify as very positive, positive, neutral, negative, very negative.\n",
        "- **Emotion detection**: Instead of the usual categories, it identifies emotions, e.g., happiness, frustration, anger, sadness, etc.\n",
        "- **Aspect-based Analysis**: Determines the sentiment about specific aspects or attributes of a product or service.\n",
        "- **Intent Analysis**: Goes beyond sentiment to determine the user's intent, e.g., interested in purchasing.\n",
        "\n",
        "---\n",
        "\n",
        "## 📚 **Applications of Sentiment Analysis**:\n",
        "\n",
        "1. **Product Reviews**: Understand how users feel about a product.\n",
        "2. **Social Media Monitoring**: Track mentions of a brand or product on social media.\n",
        "3. **Customer Feedback**: Quickly categorize feedback as positive, negative, or neutral.\n",
        "4. **Market Research**: Analyze sentiments in open-ended survey responses.\n",
        "\n",
        "---\n",
        "\n",
        "## 💡 **Insights from Sentiment Analysis**:\n",
        "\n",
        "1. **Product Improvement**: Understanding which features users love or dislike.\n",
        "2. **Customer Service**: Prioritize support for negative reviews or feedback.\n",
        "3. **Competitive Analysis**: Understand how users perceive competitors.\n",
        "4. **Content Creation**: Create content that resonates with the audience's sentiment.\n",
        "\n",
        "---\n",
        "\n",
        "## 🛑 **Challenges in Sentiment Analysis**:\n",
        "\n",
        "1. **Sarcasm & Irony**: \"Oh, great! Another flat tire.\" – Textually positive, but the intent is negative.\n",
        "2. **Contextual Sentiment**: \"The movie's plot had too many twists.\" – Is this positive or negative?\n",
        "3. **Domain-specific Jargon**: Words might have different sentiments in different domains.\n",
        "4. **Short Texts**: Texts like tweets that are too short may not provide enough information for accurate analysis.\n",
        "\n",
        "---\n",
        "\n",
        "## 🧪 **Sentiment Analysis in spaCy**:\n",
        "\n",
        "While spaCy provides tokenization and other NLP functionalities, for sentiment analysis, integration with other libraries like TextBlob or VADER is common. Here's a simple example using TextBlob:\n",
        "\n",
        "```python\n",
        "from textblob import TextBlob\n",
        "text = \"I love this product!\"\n",
        "blob = TextBlob(text)\n",
        "print(blob.sentiment)\n"
      ],
      "metadata": {
        "id": "OFi8V7ZHg1SH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IBGEZ-gkMdIm",
        "outputId": "af49514d-e3c6-46f9-bb18-e7bae323b29a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "6QyUzeQpMXSC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "PRACTICAL"
      ],
      "metadata": {
        "id": "XZevPbktHYrd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Dvm6MXMyHYqA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "RoYjSC72HYnT"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lhoqwdKmAvIS"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "_ijEvgiMgpNS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d70583f3-089a-4c30-859e-bf694097f22d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: textblob in /usr/local/lib/python3.10/dist-packages (0.17.1)\n",
            "Requirement already satisfied: nltk>=3.1 in /usr/local/lib/python3.10/dist-packages (from textblob) (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk>=3.1->textblob) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk>=3.1->textblob) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk>=3.1->textblob) (2023.6.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk>=3.1->textblob) (4.66.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install textblob\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n"
      ],
      "metadata": {
        "id": "zi1byhK0Pj75",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7222597a-effa-421b-b612-51767f4f44b8"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import json\n",
        "\n",
        "from textblob import TextBlob\n",
        "\n",
        "# Load the JSON file\n",
        "with open('/content/TINUBU.json', 'r') as file:\n",
        "    data = json.load(file)\n",
        "\n",
        "comments = data  # Assuming direct list of comments in the JSON\n",
        "\n",
        "sentiments = []\n",
        "\n",
        "# Extract comment text and perform sentiment analysis\n",
        "for comment_dict in comments:\n",
        "    comment_text = comment_dict['text']\n",
        "    analysis = TextBlob(comment_text)\n",
        "\n",
        "    # Classify the polarity\n",
        "    if analysis.sentiment.polarity > 0:\n",
        "        sentiments.append('P')  # Positive\n",
        "    elif analysis.sentiment.polarity == 0:\n",
        "        sentiments.append('O')  # Neutral\n",
        "    else:\n",
        "        sentiments.append('N')  # Negative\n",
        "\n",
        "# Save results to a CSV file\n",
        "output_path = '/content/Tinubu_sentiments.csv'\n",
        "with open(output_path, 'w', newline='', encoding='utf-8') as csvfile:\n",
        "    writer = csv.writer(csvfile)\n",
        "    writer.writerow([\"Comment\", \"Sentiment\"])  # CSV header\n",
        "    writer.writerows(zip([c['text'] for c in comments], sentiments))\n",
        "\n",
        "print(f\"Sentiments saved to {output_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "myuwNDcuS9ZL",
        "outputId": "3224d190-2c8f-44fd-da46-534907b70e4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentiments saved to /content/Tinubu_sentiments.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "from textblob import TextBlob\n",
        "\n",
        "def analyze_sentiment(input_csv_path, output_csv_path):\n",
        "    words_sentiments = []\n",
        "\n",
        "    # Load the comments from the CSV file\n",
        "    with open(input_csv_path, 'r', encoding='utf-8') as csvfile:\n",
        "        reader = csv.DictReader(csvfile)\n",
        "        for row in reader:\n",
        "            comment = row['text']  # Assuming the column name in CSV is 'text'\n",
        "            tokens = comment.split()  # Tokenizing by whitespace for simplicity\n",
        "\n",
        "            for word in tokens:\n",
        "                analysis = TextBlob(word)\n",
        "\n",
        "                # Classify the polarity of the word\n",
        "                if analysis.sentiment.polarity > 0:\n",
        "                    sentiment = 'Positive'\n",
        "                elif analysis.sentiment.polarity == 0:\n",
        "                    sentiment = 'Neutral'\n",
        "                else:\n",
        "                    sentiment = 'Negative'\n",
        "\n",
        "                words_sentiments.append((word, sentiment))\n",
        "\n",
        "    # Save the word sentiments to a new CSV file\n",
        "    with open(output_csv_path, 'w', newline='', encoding='utf-8') as csvfile:\n",
        "        writer = csv.writer(csvfile)\n",
        "        writer.writerow([\"Word\", \"Sentiment\"])  # CSV header\n",
        "        writer.writerows(words_sentiments)\n",
        "\n",
        "    print(f\"Sentiments saved to {output_csv_path}\")\n",
        "\n",
        "# Run sentiment analysis\n",
        "analyze_sentiment('/content/drive/MyDrive/TINUBU.csv', '/content/TINUBU_Word_sentiments.csv')\n"
      ],
      "metadata": {
        "id": "PUDMeXfzS9QZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1afa447-e90e-4cde-85cd-ec9bdf4ef969"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentiments saved to /content/TINUBU_Word_sentiments.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4i10V_mG-1ZW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.sentiment import SentimentIntensityAnalyzer\n",
        "nltk.download('vader_lexicon')  # Download VADER lexicon\n",
        "\n",
        "def analyze_sentiment_with_vader(input_txt_path, output_csv_path):\n",
        "    words_sentiments = []\n",
        "\n",
        "    # Initialize VADER's SentimentIntensityAnalyzer\n",
        "    sia = SentimentIntensityAnalyzer()\n",
        "\n",
        "    # Load the corpus from the .txt file\n",
        "    with open(input_txt_path, 'r', encoding='utf-8') as txtfile:\n",
        "        content = txtfile.read()\n",
        "        tokens = content.split()  # Tokenizing by whitespace\n",
        "\n",
        "        for word in tokens:\n",
        "            sentiment_score = sia.polarity_scores(word)[\"compound\"]\n",
        "\n",
        "            # Classify the sentiment based on VADER's compound score\n",
        "            if sentiment_score > 0.05:\n",
        "                sentiment = 'Positive'\n",
        "            elif sentiment_score < -0.05:\n",
        "                sentiment = 'Negative'\n",
        "            else:\n",
        "                sentiment = 'Neutral'\n",
        "\n",
        "            words_sentiments.append((word, sentiment))\n",
        "\n",
        "    # Save the word sentiments to a .csv file\n",
        "    with open(output_csv_path, 'w', newline='', encoding='utf-8') as csvfile:\n",
        "        writer = csv.writer(csvfile)\n",
        "        writer.writerow([\"Word\", \"Sentiment\"])  # CSV header\n",
        "        writer.writerows(words_sentiments)\n",
        "\n",
        "    print(f\"Sentiments saved to {output_csv_path}\")\n",
        "\n",
        "# Run sentiment analysis\n",
        "analyze_sentiment_with_vader('/content/TINUBU_CORPUS.txt', '/content/Tinubu_Vadar_sentiments.csv')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YRzymzv1-2Ji",
        "outputId": "b970bc07-f532-4627-afaa-41fc46fbc25a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentiments saved to /content/Tinubu_Vadar_sentiments.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uSMOX5E9AxnO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "from textblob import TextBlob\n",
        "import csv\n",
        "\n",
        "def analyze_sentiment(input_txt_path, output_csv_path):\n",
        "    words_sentiments = []\n",
        "\n",
        "    # Load spaCy's English model\n",
        "    nlp = spacy.load(\"en_core_web_sm\")\n",
        "    nlp.max_length = 3000000  # Adjust based on your text's length and available memory\n",
        "\n",
        "    # Tokenize the content using spaCy\n",
        "    with open(input_txt_path, 'r', encoding='utf-8') as txtfile:\n",
        "        content = txtfile.read()\n",
        "        doc = nlp(content)\n",
        "\n",
        "        # Analyze sentiment of each word using TextBlob\n",
        "        for token in doc:\n",
        "            word = token.text\n",
        "            analysis = TextBlob(word)\n",
        "            if analysis.sentiment.polarity > 0:\n",
        "                sentiment = 'Positive'\n",
        "            elif analysis.sentiment.polarity == 0:\n",
        "                sentiment = 'Neutral'\n",
        "            else:\n",
        "                sentiment = 'Negative'\n",
        "            words_sentiments.append((word, sentiment))\n",
        "\n",
        "    # Save the word sentiments to a new CSV file\n",
        "    with open(output_csv_path, 'w', newline='', encoding='utf-8') as csvfile:\n",
        "        writer = csv.writer(csvfile)\n",
        "        writer.writerow([\"Word\", \"Sentiment\"])  # CSV header\n",
        "        writer.writerows(words_sentiments)\n",
        "\n",
        "    print(f\"Sentiments saved to {output_csv_path}\")\n",
        "\n",
        "\n",
        "\n",
        "# Run sentiment analysis\n",
        "analyze_sentiment('//content/drive/MyDrive/Tinubu_Corpus.txt', '/content/Tinubu_Spacy_sentiments.csv')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ILvuNsjpAyPX",
        "outputId": "dbe1807e-ecdd-4dcb-dbba-dec534b7a779"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentiments saved to /content/Tinubu_Spacy_sentiments.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ThhRMYcGEyag"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}